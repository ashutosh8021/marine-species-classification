# -*- coding: utf-8 -*-
"""Marine Species Classifier using Deep Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FBxn6e1rQ8msVECg1YBdJuizbPexzQmi
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip "/content/drive/MyDrive/archive.zip" -d "/content/marine_species"

import os
from collections import Counter

data_dir = '/content/marine_species/Fish_Data/images/cropped'
files = os.listdir(data_dir)

# Extract species names from filenames by removing the trailing _number.png
species_names = [f.rsplit('_', 1)[0] for f in files if f.endswith('.png')]

# Count images per species
species_counts = Counter(species_names)

print("Species and their image counts:\n")
for species, count in species_counts.items():
    print(f"{species}: {count} images")

import os
import shutil
from sklearn.model_selection import train_test_split

data_dir = '/content/marine_species/Fish_Data/images/cropped'
output_dir = '/content/marine_species/split_data'
os.makedirs(output_dir, exist_ok=True)

# Get species and their image paths
image_files = [f for f in os.listdir(data_dir) if f.endswith('.png')]
species_to_files = {}

for f in image_files:
    species = f.rsplit('_', 1)[0]
    species_to_files.setdefault(species, []).append(f)

# Split and copy
for species, files in species_to_files.items():
    train_files, test_files = train_test_split(files, test_size=0.2, random_state=42)
    for split, split_files in [('train', train_files), ('test', test_files)]:
        split_dir = os.path.join(output_dir, split, species)
        os.makedirs(split_dir, exist_ok=True)
        for f in split_files:
            shutil.copy(os.path.join(data_dir, f), os.path.join(split_dir, f))

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader

# Data transforms
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
])

# Dataset
train_data = ImageFolder(root=os.path.join(output_dir, 'train'), transform=transform)
test_data = ImageFolder(root=os.path.join(output_dir, 'test'), transform=transform)

train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

# Simple CNN
class CNN(nn.Module):
    def __init__(self, num_classes):
        super(CNN, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)
        )
        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.Linear(32 * 32 * 32, 128),
            nn.ReLU(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.conv(x)
        return self.fc(x)

model = CNN(num_classes=len(train_data.classes))

import torch.optim as optim

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
for epoch in range(5):  # can increase
    model.train()
    total_loss = 0
    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1}, Loss: {total_loss:.4f}")

from sklearn.metrics import classification_report

model.eval()
y_true, y_pred = [], []

with torch.no_grad():
    for imgs, labels in test_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        outputs = model(imgs)
        preds = torch.argmax(outputs, dim=1)
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(preds.cpu().numpy())

print(classification_report(y_true, y_pred, target_names=train_data.classes))

import os

data_dir = '/content/marine_species/Fish_Data/images/cropped'
class_names = sorted(os.listdir(data_dir))

import matplotlib.pyplot as plt

def visualize_predictions(model, dataloader, class_names, device):
    model.eval()
    images, labels = next(iter(dataloader))

    images = images.to(device)
    labels = labels.to(device)

    with torch.no_grad():
        outputs = model(images)
        _, preds = torch.max(outputs, 1)

    plt.figure(figsize=(12, 8))
    for i in range(6):
        ax = plt.subplot(2, 3, i + 1)
        img = images[i].cpu().permute(1, 2, 0).numpy()
        plt.imshow(img)
        plt.title(f"True: {class_names[labels[i]]}\nPred: {class_names[preds[i]]}")
        plt.axis("off")

    plt.tight_layout()
    plt.show()

import torchvision.models as models
import torch.nn as nn

model = models.resnet18(pretrained=True)
num_classes = len(class_names)  # Based on your species
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

from torchvision import transforms

train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(),
    transforms.ToTensor(),
])

test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

pip install torchcam

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
from torchcam.methods import GradCAM
from torchcam.utils import overlay_mask
from torchvision.transforms.functional import to_pil_image
from PIL import Image

import os

data_dir = "/content/marine_species/Fish_Data/images/cropped"
class_names = sorted(os.listdir(data_dir))
num_classes = len(class_names)
print(f"Number of classes: {num_classes}")

from torchvision.models import resnet18
import torch.nn as nn

# ... (other imports and code)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = resnet18(pretrained=True)

import os
from torchvision import transforms
from PIL import Image

# Define the transform with normalization
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Example: load from file path - MODIFIED to use a valid image path
# Replace 'Salmon/image_001.jpg' with the actual path of an image file
data_dir = '/content/marine_species/Fish_Data/images/cropped'

# Get all files directly in data_dir, not just subfolders
image_files = [f for f in os.listdir(data_dir) if f.endswith('.jpg')]

# Check if there are any image files
if not image_files:
    raise FileNotFoundError(f"No .jpg images found in {data_dir}. Please check the directory.")

img_path = os.path.join(data_dir, image_files[0])  # Use the first image found
print(img_path) # Print the image path to verify

img = Image.open(img_path).convert('RGB') # Ensure RGB format

# Check if the image is grayscale and convert if needed
if img.mode == 'L':
    img = transforms.Grayscale(num_output_channels=3)(img)

input_tensor = transform(img).unsqueeze(0)  # add batch dimension

"""!pip install torchcam

"""

from torchcam.methods import GradCAM
from torchcam.utils import overlay_mask
from torchvision.transforms.functional import to_pil_image
import matplotlib.pyplot as plt

# Set up Grad-CAM on the last convolutional layer
cam_extractor = GradCAM(model, target_layer='layer4')  # 'layer4' is last conv block in ResNet18

# Forward pass through the model
out = model(input_tensor)

# Get predicted class index
class_idx = out.squeeze(0).argmax().item()
print(f"Predicted class: {class_names[class_idx]}")

# Extract CAM for the predicted class
activation_map = cam_extractor(class_idx, out)

# Overlay CAM on the original image
result = overlay_mask(to_pil_image(input_tensor.squeeze().cpu()), to_pil_image(activation_map[0].squeeze().cpu(), mode='F'), alpha=0.5)

# Show the result
plt.imshow(result)
plt.title(f"Predicted: {class_names[class_idx]}")
plt.axis('off')
plt.show()

result.save("gradcam_result.jpg")
print("Heatmap saved as gradcam_result.jpg")